import io
import base64
import json
import torch
import cv2
import os
import warnings
from PIL import Image
from facenet_pytorch import MTCNN, InceptionResnetV1

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# è®¾ç½®ä¸ºå½“å‰è„šæœ¬ç›®å½•ä¸‹çš„ JSON è·¯å¾„
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
JSON_LIBRARY_PATH = os.path.join(BASE_DIR, "face_library.json")

# åˆå§‹åŒ–è®¾å¤‡
torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# åˆå§‹åŒ–äººè„¸æ£€æµ‹ä¸è¯†åˆ«æ¨¡å‹
mtcnn = MTCNN(image_size=160, keep_all=False, device=torch_device)
resnet = InceptionResnetV1(pretrained='vggface2').eval().to(torch_device)

def pil_to_datauri(pil_img, fmt="PNG"):
    buf = io.BytesIO()
    pil_img.save(buf, format=fmt)
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    return f"data:image/{fmt.lower()};base64,{b64}"

def get_embedding_and_face_from_frame(frame):
    """
    ä» OpenCV å›¾åƒå¸§æå–äººè„¸å’ŒåµŒå…¥å‘é‡ã€‚
    """
    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    face_tensor = mtcnn(img)
    if face_tensor is None:
        return None, None
    emb = resnet(face_tensor.unsqueeze(0).to(torch_device)).detach()
    return emb, face_tensor

def tensor_to_image(tensor):
    img = tensor.permute(1, 2, 0).cpu().numpy()
    img = (img - img.min()) / (img.max() - img.min())
    return (img * 255).astype('uint8')

def find_top_matches_facenet(tgt_emb, top_k=10):
    with open(JSON_LIBRARY_PATH, 'r', encoding='utf-8') as f:
        candidates = json.load(f)

    scored = []
    for c in candidates:
        emb = torch.tensor(c["embedding"]).unsqueeze(0).to(torch_device)
        sim = torch.nn.functional.cosine_similarity(tgt_emb.to(torch_device), emb).item()
        scored.append((sim, c))

    top_matches = sorted(scored, key=lambda x: x[0], reverse=True)[:top_k]
    return top_matches

def capture_and_compare():
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return

    print("ğŸ“· æ‰“å¼€æ‘„åƒå¤´æˆåŠŸï¼è¯·è¾“å…¥å‘½ä»¤ï¼š\n  s - æ‹ç…§è¯†åˆ«\n  q - é€€å‡ºç¨‹åº")
    while True:
        cmd = input("\nè¯·è¾“å…¥æ“ä½œæŒ‡ä»¤ï¼ˆs/qï¼‰ï¼š").strip().lower()
        if cmd == 'q':
            print("ğŸ‘‹ å·²é€€å‡ºæ‘„åƒå¤´è¯†åˆ«")
            break
        elif cmd == 's':
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                continue

            # ä¿å­˜å½“å‰å¸§
            cv2.imwrite("temp_frame.jpg", frame)
            print("ğŸ“¸ å›¾åƒå·²ä¿å­˜ä¸º temp_frame.jpgï¼Œæ­£åœ¨å¤„ç†äººè„¸...")

            emb, tgt_uri = get_embedding_and_face_from_frame(frame)
            if emb is None:
                print("âš ï¸ æœªæ£€æµ‹åˆ°äººè„¸ï¼Œè¯·é‡è¯•")
                continue

            print("ğŸ” æ­£åœ¨è¯†åˆ«ï¼Œè¯·ç¨å€™...")
            matches = find_top_matches_facenet(emb, top_k=10)

            print("\nâœ… åŒ¹é…ç»“æœï¼ˆTop 10ï¼‰ï¼š")
            for rank, (score, match) in enumerate(matches, 1):
                print(f"{rank}. å§“å: {match['name']} | å­¦å·: {match['student_id']} | ç›¸ä¼¼åº¦: {score:.4f}")
        else:
            print("âš ï¸ æ— æ•ˆæŒ‡ä»¤ï¼Œè¯·è¾“å…¥ 's' æˆ– 'q'")

    cap.release()

if __name__ == "__main__":
    capture_and_compare()
